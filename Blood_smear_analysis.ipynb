{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This Notebook was made by Niranjan and Hrishika Rai, for a research internship at center of excellence, RVCE.*\n",
    "\n",
    "*Reach us out at:-*\n",
    "\n",
    "\n",
    "*Niranjan - avulapatin@rvce.edu.in*\n",
    "\n",
    "*Hrishika - hrishikarai.cs18@rvce.edu.in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4OSA5UzTMzbD"
   },
   "source": [
    "# **Blood smear analysis**\n",
    "\n",
    "In order to  use the model, first download the appropriate weights files from the link given below.\n",
    "\n",
    "Link to weights files :- https://drive.google.com/drive/folders/1Ej-Os4KFqN2antjvcEK27iHt8lQJvUIl?usp=sharing\n",
    "\n",
    "\n",
    "Make sure all your test images are of 416*416 dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzfaGolQyBpF"
   },
   "source": [
    "## Import and install all the YOLO-v5 dependencies, by running the below cell. \n",
    "\n",
    "Make sure to use a GPU. (Runtime -> Change runtime type -> GPU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5eJJPyuPNw3"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 \n",
    "!pip install -qr yolov5/requirements.txt \n",
    "%cd yolov5\n",
    "\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  \n",
    "from utils.google_utils import gdrive_download \n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ne48WMs4yzcw"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Modify the custom_detect.py file by modifying the parameters in the below cell.\n",
    "\n",
    "You can modify the following parameters:-\n",
    "\n",
    "\n",
    "*   Bounding box border thickness, at line 144\n",
    "\n",
    "\n",
    "```\n",
    "    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "```\n",
    "\n",
    "\n",
    "*   IOU threshold, at line 156\n",
    "\n",
    "\n",
    "```\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n",
    "```\n",
    "\n",
    "\n",
    "*   Confidence threshold, at line 157\n",
    "\n",
    "\n",
    "```\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.4, help='object confidence threshold')\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnMrujMOQ-Wb"
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-H2F8t57QvbO"
   },
   "outputs": [],
   "source": [
    "%%writetemplate /content/yolov5/custom_detect.py\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords,\n",
    "    xyxy2xywh, plot_one_box, strip_optimizer, set_logging)\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "\n",
    "def detect(save_img=False):\n",
    "    out, source, weights, view_img, save_txt, imgsz = \\\n",
    "        opt.output, opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size\n",
    "    webcam = source.isnumeric() or source.startswith('rtsp') or source.startswith('http') or source.endswith('.txt')\n",
    "\n",
    "    # Initialize\n",
    "    set_logging()\n",
    "    device = select_device(opt.device)\n",
    "    if os.path.exists(out):\n",
    "        shutil.rmtree(out)  # delete output folder\n",
    "    os.makedirs(out)  # make new output folder\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model'])  # load weights\n",
    "        modelc.to(device).eval()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    if webcam:\n",
    "        view_img = True\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz)\n",
    "    else:\n",
    "        save_img = True\n",
    "        dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "    # Run inference\n",
    "    t0 = time.time()\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply Classifier\n",
    "        if classify:\n",
    "            pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n",
    "            else:\n",
    "                p, s, im0 = path, '', im0s\n",
    "\n",
    "            save_path = str(Path(out) / Path(p).name)\n",
    "            txt_path = str(Path(out) / Path(p).stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')\n",
    "            s += '%gx%g ' % img.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += '%g %ss, ' % (n, names[int(c)])  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        with open(txt_path + '.txt', 'a') as f:\n",
    "                            f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "\n",
    "                    if save_img or view_img:  # Add bbox to image\n",
    "                        label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
    "\n",
    "            # Stream results\n",
    "            if view_img:\n",
    "                cv2.imshow(p, im0)\n",
    "                if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'images':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "\n",
    "                        fourcc = 'mp4v'  # output video codec\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "\n",
    "    if save_txt or save_img:\n",
    "        print('Results saved to %s' % Path(out))\n",
    "        if platform.system() == 'Darwin' and not opt.update:  # MacOS\n",
    "            os.system('open ' + save_path)\n",
    "\n",
    "    print('Done. (%.3fs)' % (time.time() - t0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default='yolov5s.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--source', type=str, default='inference/images', help='source')  # file/folder, 0 for webcam\n",
    "    parser.add_argument('--output', type=str, default='inference/output', help='output folder')  # output folder\n",
    "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.4, help='object confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--view-img', action='store_true', help='display results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
    "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--update', action='store_true', help='update all models')\n",
    "    opt = parser.parse_args()\n",
    "    print(opt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if opt.update:  # update all models (to fix SourceChangeWarning)\n",
    "            for opt.weights in ['yolov5s.pt', 'yolov5m.pt', 'yolov5l.pt', 'yolov5x.pt']:\n",
    "                detect()\n",
    "                strip_optimizer(opt.weights)\n",
    "        else:\n",
    "            detect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aoIMAs70tq9"
   },
   "source": [
    "## Run the model\n",
    "Change the path to weights file and images accordingly and run the below cell.\n",
    "\n",
    "The number of predicted RBC, WBC and platelets is shown next to each image's name in the output of below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki0naniHMvBq"
   },
   "outputs": [],
   "source": [
    "!python custom_detect.py --weights \"PATH TO WEIGHTS FILE\" --img 416 --conf 0.1 --source \"PATH TO IMAGE FILE OR FOLDER CONTAINING IMAGES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5p2CdXmxvpn"
   },
   "source": [
    "## Visualising images\n",
    "You can find the predicted images in at /content/yolov5/inference/output.\n",
    "\n",
    "Run the below cell to visualize them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWwKynU_PEdd"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/yolov5/inference/output/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu8J1uK_Q6D8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Blood smear analysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
